проект data sience
Из «Бета-Банка» стали уходить клиенты. Каждый месяц. Немного, но заметно. Банковские маркетологи посчитали: сохранять текущих клиентов дешевле, чем привлекать новых.

Нужно спрогнозировать, уйдёт клиент из банка в ближайшее время или нет. Вам предоставлены исторические данные о поведении клиентов и расторжении договоров с банком.

В этом проекте были использованы модели машинного обучения: решающее древо, случайный лес и логистическая регрессия. 

Перед тем, как разделять выборку на обучающую, валидационную и тестовую, была проведена предварительная подготовка датасета:

заполнены пропуски в данных удалены 2 категориальных столбца CustomerId и Surname + RowNumber, так как они никак не влияют на качество обучения (а если и влияют, то только в негативном ключе) дополнительно проведена проверка на наличие сильной мультиколлинеарность (подтвердилось ее отстутствие) 2 категориальных признака (Gender, Geography) были преобразованы в бинарные при помощи техники One-Hot Ecnoding к 3 количественным признакам (CreditScore, Balance и EstimatedSalary) было применено масштабирование, чтобы при обучении не получилось так, что какой-то признак с более высоким значением был засчитан как более значимый.

C помощью матриц ошибок можно явно увидеть, что несмотря на достаточно высокое значение accuracy, для всех трех моделей наблюдается остаточно сильный дисбаланс классов. К примеру, для моделей Дерево решений и Случайный лес ситуация схожая - факт того, что клиент не ушел (0), модели определяют правильно примерно в 95% случаев, в то время как результат предсказаний по факту ухода (1) в среднем всего 45%.

В рамках борьбы с дисбалансом классов было рассмотрено 3 метода:

Взвешивание классов Увеличение выборки (upsampling) Уменьшение выборки (downsampling)

В результате борьбы с дисбанансом классов были получены следующие выводы:

Уменьшение и увеличение выборки позволяют достичь примерно одинаковое значение F1-score. Наибольшее значение метрики F1-score получено на модели Случайный лес при помощи взвешивания классов. Поэтому для финального тестирования была использована именно она. Значение метрики AUC-ROC всегда стабильно выше F1-score и колеблется в районе 80%. Далее, наилучшая модель была протестирована на тестовой выборке. Значения ключевых метрик получились следующие:

F1-score = 0.63 (выше необходимого значения) AUC-ROC = 0.86 (достаточно близко к единице)